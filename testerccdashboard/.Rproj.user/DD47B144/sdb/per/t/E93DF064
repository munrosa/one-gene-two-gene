{
    "contents" : "%\\VignetteIndexEntry{Analysing RNA-Seq data with the \"DESeq\" package}\n%\\VignettePackage{DESeq}\n\n% To compile this document\n% library('cacheSweave');rm(list=ls());Sweave('DESeq.Rnw',driver=cacheSweaveDriver());system(\"pdflatex DESeq\")\n\n\\documentclass[10pt,oneside]{article}\n\n\\newcommand{\\thetitle}{Differential expression of RNA-Seq data at the gene level -- the DESeq package}\n%\\usepackage[pdftitle={\\thetitle},pdfauthor={Wolfgang Huber}]{whbiocvignette}\n\\usepackage{whbiocvignette}\n\n\\title{\\textsf{\\textbf{\\thetitle}}}\n\\author{Simon Anders$^1$, Wolfgang Huber\\\\[1em]European Molecular Biology Laboratory (EMBL),\\\\ Heidelberg, Germany\\\\\n\\texttt{$^1$sanders@fs.tum.de}}\n\n% The following command makes use of SVN's 'Date' keyword substitution\n% To activate this, I used: svn propset svn:keywords Date DESeq.Rnw\n\\date{\\Rpackage{DESeq} version \\Sexpr{packageDescription(\"DESeq\")$Version}  (Last revision \\StrMid{$Date: 2013-02-24 15:13:24 -0800 (Sun, 24 Feb 2013) $}{8}{18})}\n\n\\SweaveOpts{keep.source=TRUE,eps=FALSE,pdf=FALSE,png=TRUE,include=FALSE,width=5.4,height=3.7,resolution=180}\n\n\\begin{document}\n\\SweaveOpts{concordance=TRUE}\n<<options,results=hide,echo=FALSE>>=\noptions(digits=3, width=100)\n@\n\n\\maketitle\n\n\\begin{abstract}\nA basic task in the analysis of count data from RNA-Seq is the detection of differentially expressed genes.\nThe count data are presented as a table which reports, for each sample, the number of reads that have been\nassigned to a gene. Analogous analyses also arise for other assay types, such as comparative ChIP-Seq.\nThe package \\Rpackage{DESeq} provides methods to test for differential\nexpression by use of the negative binonial distribution and a shrinkage estimator for the distribution's\n variance\\footnote{Other Bioconductor packages with similar aims are \\Rpackage{edgeR} and \\Rpackage{baySeq}.}.\nThis vignette explains the use of the package. For an exposition of\nthe statistical method, please see our paper~\\cite{Anders:2010:GB} and the additional information in\nSection~\\ref{sec:changes}.\n\\end{abstract}\n\n\\tableofcontents\n\n%--------------------------------------------------\n\\section{Input data and preparations} \\label{sec:prep}\n%--------------------------------------------------\n\\subsection{The count table}\n%--------------------------------------------------\nAs input, the \\Rpackage{DESeq} package expects count data as\nobtained, e.\\,g., from RNA-Seq or another high-throughput\nsequencing experiment, in the form of a rectangular table of integer values.\nThe table cell in the $i$-th row and the\n$j$-th column of the table tells how many reads have been mapped to\ngene $i$ in sample $j$. Analogously, for other types of assays, the\nrows of the table might correspond e.\\,g.\\ to binding regions (with\nChIP-Seq) or peptide sequences (with quantitative mass spectrometry).\n\nThe count values must be raw counts of sequencing\nreads. This is important for \\Rpackage{DESeq}'s statistical model to\nhold, as only the actual counts allow assessing the measurement\nprecision correctly. Hence, please do do not supply other quantities,\nsuch as (rounded) normalized counts, or counts of covered base pairs\n-- this will only lead to nonsensical results.\n\nFurthermore, it is important that each column stems from an\nindependent biological replicate.  For technical replicates (e.\\,g.\\\nwhen the same library preparation was distributed over multiple lanes\nof the sequencer), please sum up their counts to get a single column,\ncorresponding to a unique biological replicate.  This is needed in\norder to allow \\Rpackage{DESeq} to estimate variability in the\nexperiment correctly.\n\nTo obtain such a count table for your own data, you will need to\ncreate it from your sequence alignments and suitable\nannotation. In Bioconductor, you can use the function\n\\Rfunction{summarizeOverlaps} in the \\Rpackage{GenomicRanges}\npackage. See the vignette, reference~\\cite{summarizeOverlaps}, for a\nworked example.  Another possibility is provided by the Bioconductor\npackage \\Rpackage{easyRNASeq}.\n\nAnother easy way to produce such a table from the output of the\naligner is to use the \\texttt{htseq-count} script distributed with the\n\\emph{HTSeq} Python package. Even though \\emph{HTSeq} is written in\nPython, you do not need to know any Python to use\n\\texttt{htseq-count}. See\n\\url{http://www-huber.embl.de/users/anders/HTSeq/doc/count.html}.\nHTSeq-count produces one count file for each sample. \\Rpackage{DESeq}\noffers the function \\Rfunction{newCountDataSetFromHTSeqCount},\ndescribed below, to get an analysis started from these files.\n\nIn this vignette, we will work with the gene level read counts from\nthe \\Rpackage{pasilla} data package. This data set is from an\nexperiment on \\emph{Drosophila melanogaster} cell cultures and\ninvestigated the effect of RNAi knock-down of the splicing factor\n\\emph{pasilla}~\\cite{Brooks2010}.  The detailed transcript of how we\nproduced the \\Rpackage{pasilla} count table from second generation\nsequencing (Illumina) FASTQ files is provided in the vignette of the\ndata package \\Rpackage{pasilla}. The table is\nsupplied by the \\Rpackage{pasilla} package as a text file of\ntab-separated values. The function \\Rfunction{system.file} tells\nus where this file is stored on your computer.\n%\n<<systemFile>>=\ndatafile = system.file( \"extdata/pasilla_gene_counts.tsv\", package=\"pasilla\" )\ndatafile\n@\n%\nHave a look at the file with a text editor to see how it is formatted. To read\nthis file with R, we use the function \\Rfunction{read.table}.\n%\n<<readTable>>=\npasillaCountTable = read.table( datafile, header=TRUE, row.names=1 )\nhead( pasillaCountTable )\n@\n%\nHere, \\texttt{header=TRUE} indicates that the first line contains column names\nand \\texttt{row.names=1} means that the first column should be used as\nrow names. This leaves us with a \\Rclass{data.frame} containing integer\ncount values.\n\n%--------------------------------------------------\n\\subsection{The metadata}\n%--------------------------------------------------\nThe best data are useless without metadata. \\Rpackage{DESeq} uses\nfamiliar idioms in Bioconductor to manage the metadata that go with\nthe count table. The metadata can be divided into three groups:\ninformation about the samples (table colums), about the features\n(table rows), and about the overall experiment.\n\nFirst, we need a description of the samples, which we keep in a\n\\Rclass{data.frame} whose columns correspond to different types of information, and whose\nrows correspond to the \\Sexpr{ncol(pasillaCountTable)} samples:\n<<pasillaDesign>>=\npasillaDesign = data.frame(\n   row.names = colnames( pasillaCountTable ),\n   condition = c( \"untreated\", \"untreated\", \"untreated\",\n      \"untreated\", \"treated\", \"treated\", \"treated\" ),\n   libType = c( \"single-end\", \"single-end\", \"paired-end\",\n      \"paired-end\", \"single-end\", \"paired-end\", \"paired-end\" ) )\n\npasillaDesign\n@\n%\nHere, simply use a chunk of R code to set up this define. More often,\nyou will read this into R from a spreadsheet table, using the\nR functions \\Rfunction{read.table} or \\Rfunction{read.csv}; or perhaps\neven from a relational database table using R's database access\nfacilities.\n\nTo analyse these samples, we will have to account for the fact that we have\nboth single-end and paired-end method. To keep things simple at the start, we defer the\ndiscussion of this to Section~\\ref{sec:GLM} and first demonstrate a simple\nanalysis by using only the paired-end samples.\n%\n<<pairedSamples>>=\npairedSamples = pasillaDesign$libType == \"paired-end\"\ncountTable = pasillaCountTable[ , pairedSamples ]\ncondition = pasillaDesign$condition[ pairedSamples ]\n@\n%\nNow, we have data input as follows.\n%\n<<>>=\nhead(countTable)\ncondition\n@\n%\nFor your own data, create such a factor simply with\n<<condition,eval=FALSE>>=\n#not run\ncondition = factor( c( \"untreated\", \"untreated\", \"treated\", \"treated\" ) )\n@\n\n<<conditionCheck,results=hide,echo=FALSE>>=\nstopifnot( identical( condition, factor( c( \"untreated\", \"untreated\", \"treated\", \"treated\" ) ) ) )\n@\n%\n\nWe can now instantiate a \\Rclass{CountDataSet}, which is the central\ndata structure in the \\Rpackage{DESeq} package:\n%\n<<instantiate, results=hide>>=\nlibrary( \"DESeq\" )\ncds = newCountDataSet( countTable, condition )\n@\n\nIf you have used \\emph{htseq-count} (see above) to obtain your read counts, you can\nuse the funtion \\Rfunction{newCountDataSetFromHTSeqCount} to obtain a CountDataSe\ndirectly from the count files produced by \\emph{htseq-count}. To this end,\nproduce a data frame, similar to \\emph{pasillaDesign} constructed above, with\nthe sample names in the first column, the file names in the scond column, and\nthe condition in the third column (or, if you have more than one factor in your design matrix,\nall these factors in the third and folling columns), and pass this data frame\nto the function. See the help page (``\\texttt{?newCountDataSetFromHTSeqCount}'')\nfor further details.\n\nThe \\Rclass{CountDataSet} class is derived from \\Rpackage{Biobase}'s\n\\Rclass{eSet} class and so shares all features of this standard\nBioconductor class. Furthermore, accessors are provided for its data\nslots\\footnote{In fact, the object \\Robject{pasillaGenes}\n  from the \\Rpackage{pasilla} package is of class \\Rclass{CountDataSet}, and we could do the subsequent\n  analysis on the basis of this object.\n  Here we re-create \\Robject{cds} from elementary data types, a \\Rclass{data.frame} and a \\Rclass{factor},\n  for pedagogic effect.}.  For example, the counts can be accessed with the\n\\Rfunction{counts} function, as we will see in the next section.\n\n%------------------------------------------------------------\n\\subsection{Normalisation}\n%------------------------------------------------------------\nAs a first processing step, we need to estimate the effective library\nsize. This step is sometimes also called \\emph{normalisation}, even\nthough there is no relation to normality or a normal\ndistribution.  The effective library size information is called the\n\\emph{size factors} vector, since the package only needs to know the\nrelative library sizes.\nIf the counts of non-differentially\nexpressed genes in one sample are, on average, twice as high as in\nanother (because the library was sequenced twice as deeply), the size factor for the first sample should be twice that\nof the other sample~\\cite{Anders:2010:GB,Anders:2012:GR}. The function\n\\Rfunction{estimateSizeFactors} estimates the size factors from the\ncount data. (See the man page of\n\\Rfunction{estimateSizeFactorsForMatrix} for technical details on the\ncalculation.)\n%\n<<estimateSizeFactors>>=\ncds = estimateSizeFactors( cds )\nsizeFactors( cds )\n@\n\nIf we divide each column of the count table by the size factor for this column, the\ncount values are brought to a common scale, making them comparable. When called\nwith \\texttt{normalized=TRUE}, the \\texttt{counts} accessor function performs this\ncalculation. This is useful, e.g., for visualization.\n%\n<<headcounts2>>=\nhead( counts( cds, normalized=TRUE ) )\n@\n\n%------------------------------------------------------------\n\\section{Variance estimation}\n%------------------------------------------------------------\n\nThe inference in \\Rpackage{DESeq} relies on an estimation of the typical\nrelationship between the data's variance and their mean, or, equivalently,\nbetween the data's dispersion and their mean.\n\nThe \\emph{dispersion} can be understood as the square of the coefficient\nof biological variation. So, if a gene's expression typically differs\nfrom replicate to replicate sample by 20\\%, this gene's dispersion is $0.2^2=.04$.\nNote that the variance seen between counts is the sum of two components: the\nsample-to-sample variation just mentioned, and the uncertainty in measuring\na concentration by counting reads. The latter, known as shot noise or Poisson\nnoise, is the dominating noise source for lowly expressed genes.\nThe former dominates for highly expressed genes.\nThe sum of both, shot noise and dispersion, is considered in the differential expression inference.\n\nHence, the variance $v$ of count values is modelled as\n\\[ v = s \\mu + \\alpha s^2\\mu^2, \\]\nwhere $\\mu$ is the expected normalized count value (estimated by the average normalized count value),\n$s$ is the size factor for the sample under consideration, and $\\alpha$ is the dispersion\nvalue for the gene under consideration.\n\nTo estimate the dispersions, use this command.\n<<estimateDispersions,cache=TRUE>>=\ncds = estimateDispersions( cds )\n@\n\nWe could now proceed straight to the testing for differetial\nexpression in Section~\\ref{sec:DE}.  However, let us first spend a\nlittle more time with looking at the results of\n\\Rfunction{estimateDispersions}, in order to better understand the\nsubsequent inference.  Also, verification of the dispersion plot\nFigure~\\ref{figFit}, explained below, is an aspect of data quality control: how well do\nthe data accord to the expectations of our analytic approach? Quality\nassessment is a crucial step of the data analysis, and we will see\nfurther quality diagnostics in Section~\\ref{sec:quality}.\n\nThe function \\Rfunction{estimateDispersions} performs three\nsteps. First, it estimates a dispersion value for each gene, then it\nfits a curve through the estimates. Finally, it assigns to each gene a\ndispersion value, using a choice between the per-gene estimate and the fitted\nvalue.  To allow the user to inspect the intermediate steps, a\n\\Robject{fitInfo} object is stored, which contains the per-gene estimate, the fitted curve\nand the values that will subsequently be used for inference.\n%\n<<str>>=\nstr( fitInfo(cds) )\n@\n%\n\\label{fitInfo}\nIt is useful to inspect the results of these steps visually.  We can\nplot the per-gene estimates against the mean normalized counts\nper gene and overlay the fitted curve by using the function\n\\Rfunction{plotDispEsts} (Fig.~\\ref{figFit}).\n%\n\\begin{figure}\n\\centering\n\\includegraphics[width=.6\\textwidth]{DESeq-figFit}\n\\caption{Empirical (black dots) and fitted (red lines) dispersion values\nplotted against the mean of the normalised counts.}\n\\label{figFit}\n\\end{figure}\n%\n<<figFit,fig=TRUE>>=\nplotDispEsts( cds )\n@\n\n% check a claim made in the paragraph below.\n<<echo=FALSE, results=hide>>=\nall(table(conditions(cds))==2)\n@\n\nAs we estimated the dispersions from a small number of replicates,\nthe estimates scatter with quite some sampling variance around their true values.\nAn initial assumption that one could make is that the regression line\nshown in Figure~\\ref{figFit} models the true underlying dispersions,\nand that the variation of the point estimates around simply reflects\nsampling variance. This is the assumption that we put forward in the\nfirst paper on \\Rpackage{DESeq}~\\cite{Anders:2010:GB}.  However,\nsubsequent experience with larger data sets indicates that not all of\nthe variability of the points around the regression line seen in\nFigure~\\ref{figFit} is sampling variance: some of it reflects\ndifferences of the true, underlying variance between different genes.\nHence, the default behaviour of \\Rpackage{DESeq} now\nuses a more prudent or conservative approach: if a per-gene estimates\nlies below the regression line, we assume that this might indeed be\nsampling variance, and shift the estimate upwards to the value\npredicted by the regression line. If, however, the per-gene\nestimate lies above the line, we do not shift it downwards to the\nline, but rather keep it as is.\n\nThe option \\texttt{sharingMode} of the function\n\\Rfunction{estimateDispersions} can be used to control this\nbehaviour. The value \\texttt{sharingMode=\"maximum\"} corresponds to the\ndefault. If you have many replicates (where \\emph{many} starts at\naround 7), the choice \\texttt{sharingMode=\"gene-est-only\"} will\ntypically be more adequate.  If you would like to use the behaviour\ndescribed in~\\cite{Anders:2010:GB}, this is achieved by specifying\n\\texttt{sharingMode=\"fit-only\"}.\n\nAnother difference of the current \\Rpackage{DESeq} version to the original method described in the\npaper is the way how the mean-dispersion relation is fitted. By default,\n\\Rfunction{estimateDispersions} now performs a parametric fit: Using a gamma-family\nGLM, two coefficients $\\alpha_0, \\alpha_1$ are found to\nparametrize the fit as $\\alpha = \\alpha_0 + \\alpha_1/\\mu$. (The values of the two\ncoefficients can be found in the \\texttt{fitInfo} object, as attribute \\texttt{coefficients}\nto \\texttt{dispFunc}.) For some data sets, the parametric fit may give bad results, in\nwhich case one should try a local fit (the method described in the paper), which\nis available via the option \\texttt{fitType=\"local\"} to \\Rfunction{estimateDispersions}.\n\nIn any case, the dispersion values which will be used by the subsequent testing are stored in\nthe feature data slot of \\texttt{cds}:\n%\n<<head>>=\nhead( fData(cds) )\n@\n%\n\\fixme{Why is the value for FBgn00000014 Inf and not 0 (given that all counts are 0)?}\nYou can verify that these values are indeed the maxima from the two value vectors\nin \\Robject{fitInfo(cds)}, which we saw on page~\\pageref{fitInfo}.\nAdvanced users who want to fiddle with the dispersion estimation can change the values\nin \\texttt{fData(cds)} prior to calling the testing function.\n\n%------------------------------------------------------------\n\\section{Inference: Calling differential expression} \\label{sec:DE}\n%------------------------------------------------------------\n\\subsection{Standard comparison between two experimental conditions}\n\nHaving estimated the dispersion for each gene, it is straight-forward to look for\ndifferentially expressed genes. To contrast two conditions, e.g., to see whether there is differential\nexpression between conditions ``untreated'' and ``treated'', we simply call the function \\Rfunction{nbinomTest}.\nIt performs the tests as described in~\\cite{Anders:2010:GB} and returns a data frame with the $p$ values and other\nuseful information.\n%\n<<nbt1,cache=TRUE>>=\nres = nbinomTest( cds, \"untreated\", \"treated\" )\n<<nbt2>>=\nhead(res)\n@\n%\n<<checkClaims,echo=FALSE,results=hide>>=\nstopifnot(identical(colnames(res), c(\"id\", \"baseMean\", \"baseMeanA\", \"baseMeanB\", \"foldChange\",\n                                     \"log2FoldChange\", \"pval\", \"padj\")))\n@\nThe interpretation of the columns of \\Rclass{\\Sexpr{class(res)}} is as follows.\n\n\\noindent\n\\begin{tabular}{lp{0.8\\textwidth}}\n\\texttt{id}&feature identifier\\\\\n\\texttt{baseMean}&mean normalised counts, averaged over all samples from both conditions\\\\\n\\texttt{baseMeanA}&mean normalised counts from condition A\\\\\n\\texttt{baseMeanB}&mean normalised counts from condition B\\\\\n\\texttt{foldChange}&fold change from condition A to B\\\\\n\\texttt{log2FoldChange}&the logarithm (to basis 2) of the fold change\\\\\n\\texttt{pval}&$p$ value for the statistical significance of this change\\\\\n\\texttt{padj}&$p$ value adjusted for multiple testing with the Benjamini-Hochberg procedure (see the R function\n\\Rfunction{p.adjust}), which controls false discovery rate (FDR)\\\\\n\\end{tabular}\n\n\\begin{figure}[ht]\n\\centering\n\\includegraphics[width=.6\\textwidth]{DESeq-figDE}\n\\caption{Plot of normalised mean versus $log_2$ fold change\nfor the contrast \\emph{untreated} versus \\emph{treated}.}\n\\label{figDE}\n\\end{figure}\n\n\\vspace{1.5ex}\nLet us first plot the $\\log_2$ fold changes against the mean normalised counts, colouring in red those genes\nthat are significant at 10\\% FDR (Figure~\\ref{figDE}).\n%\n<<figDE,fig=TRUE>>=\nplotMA(res)\n@ %$\n%\n\\begin{figure}[ht]\n\\centering\n\\includegraphics[width=.6\\textwidth]{DESeq-histp}\n\\caption{Histogram of $p$-values from the call to nbinomTest.}\n\\label{fighistp}\n\\end{figure}\n\nIt is also instructive to look at the histogram of $p$ values (Figure~\\ref{fighistp}).\nThe enrichment of low $p$ values stems from the differentially expressed genes,\nwhile those not differentially expressed are spread uniformly over the range\nfrom zero to one (except for the $p$ values from genes with very low counts, which\ntake discrete values and so give rise to high counts for some bins at the right.)\n%\n<<histp,fig=TRUE>>=\nhist(res$pval, breaks=100, col=\"skyblue\", border=\"slateblue\", main=\"\")\n@\n\nWe can filter for significant genes, according to some chosen threshold for the false dicovery rate (FDR),\n<<ressig1>>=\nresSig = res[ res$padj < 0.1, ]\n@\nand list, e.\\,g., the most significantly differentially expressed genes:\n<<ressig2>>=\nhead( resSig[ order(resSig$pval), ] )\n@\n\nWe may also want to look at the most strongly down-regulated of the significant\ngenes,\n<<ressig3>>=\nhead( resSig[ order( resSig$foldChange, -resSig$baseMean ), ] )\n@\nor at the most strongly up-regulated ones:\n<<ressig4>>=\nhead( resSig[ order( -resSig$foldChange, -resSig$baseMean ), ] )\n@\n\nTo save the output to a file, use the R functions \\Rfunction{write.table} and\n\\Rfunction{write.csv}. (The latter is useful if you want to load the table in a\nspreadsheet program such as Excel.)\n\n<<writetable>>=\nwrite.csv( res, file=\"My Pasilla Analysis Result Table.csv\" )\n@\n\n\\begin{figure}[ht]\n\\centering\n\\includegraphics[width=.6\\textwidth]{DESeq-MArepl}\n\\caption{Plot of the log2 fold change between the untreated replicates\nversus average expression strength.}\n\\label{figMArepl}\n\\end{figure}\n\nNote in Fig.~\\ref{figDE} how the power to detect significant differential expression depends on\nthe expression strength. For weakly expressed genes, stronger changes are\nrequired for the gene to be called significantly expressed. To understand the reason for\nthis let, us compare the normalized counts between two replicate samples, here\ntaking the two untreated samples as an example:\n%\n<<ncu>>=\nncu = counts( cds, normalized=TRUE )[ , conditions(cds)==\"untreated\" ]\n@\n\\Robject{ncu} is now a matrix with two columns.\n%\n<<MArepl,fig=TRUE>>=\nplotMA(data.frame(baseMean = rowMeans(ncu),\n                  log2FoldChange = log2( ncu[,2] / ncu[,1] )),\n       col = \"black\")\n@\n%\nAs one can see in Figure~\\ref{figMArepl}, the log fold changes between replicates\nare stronger for lowly expressed genes than for highly expressed ones. We\nought to conclude that a gene's expression is influenced by the treatment only\nif the change between treated and untreated samples is stronger than\nwhat we see between replicates, and hence, the dividing line between red and black in\nFigure~\\ref{figDE} mimics the shape seen in Figure~\\ref{figMArepl}.\n\n%------------------------------------------------------------\n\\subsection{Working partially without replicates}\n%------------------------------------------------------------\n\nIf you have replicates for one condition but not for the other, you can still proceed as\nbefore. In such cases only the conditions with replicates will be used to estimate the dispersion.\nOf course, this is only valid if you have good reason to believe that the unreplicated\ncondition does not have larger variation than the replicated one.\n\nTo demonstrate, we subset our data object to only three samples:\n\n<<subset>>=\ncdsUUT = cds[ , 1:3]\npData( cdsUUT )\n@\n\n\\begin{figure}[ht]\n\\centering\n\\includegraphics[width=.6\\textwidth]{DESeq-figDE_Tb}\n\\caption{MvA plot for the contrast ``treated'' vs.\\ ``untreated'', using two treated and\nonly one untreated sample.}\n\\label{figDE_Tb}\n\\end{figure}\n\nNow, we do the analysis as before.\n\n<<est123,cache=TRUE>>=\ncdsUUT = estimateSizeFactors( cdsUUT )\ncdsUUT = estimateDispersions( cdsUUT )\nresUUT = nbinomTest( cdsUUT, \"untreated\", \"treated\" )\n@\n\nWe produce the analogous plot as before, again with\n<<figDE_Tb,fig=TRUE>>=\nplotMA(resUUT)\n@ %$\nFigure~\\ref{figDE_Tb} shows the same symmetry in up- and down-regulation\nas in Fig.~\\ref{figDE}, but a certain asymmetry in the boundary line for significance. This\nhas an easy explanation: low counts suffer from proportionally stronger shot noise than high\ncounts, and since there is only one ``untreated'' sample versus two ``treated'' ones,\na stronger downward fold-change is required to be called significant than for the upward direction.\n\n%--------------------------------------------------\n\\subsection{Working without any replicates}\n%--------------------------------------------------\n\nProper replicates are essential to interpret a biological experiment. After all, if one compares two\nconditions and finds a difference, how else can one know that this difference is due to the different conditions\nand would not have arisen between replicates, as well, just due to experimental or biological noise? Hence, any attempt to work without\nreplicates will lead to conclusions of very limited reliability.\n\nNevertheless, such experiments are sometimes undertaken, and the \\Rpackage{DESeq} package\ncan deal with them, even though the soundness of the results may depend much on the circumstances.\n\nOur primary assumption is now that the mean is a good predictor for the dispersion.\nOnce we accept this assumption, we may argue as follows: Given two samples from\ndifferent conditions and a number of genes with comparable expression levels, of which we expect only a minority\nto be influenced by the condition, we may take the dispersion estimated from comparing their counts \\emph{across}\nconditions as ersatz for a proper estimate of the variance across replicates. After all,\nwe assume most genes to behave the same within replicates as across conditions, and hence, the estimated variance\nshould not be affected too much by the influence of the hopefully few differentially expressed genes. Furthermore,\nthe differentially expressed genes will only cause the dispersion estimate to be too high, so that the test will err to the\nside of being too conservative.\n\nWe shall now see how well this works for our example data.\nWe reduce our count data set to just two columns, one ``untreated'' and one ``treated'' sample:\n<<subset2>>=\ncds2 = cds[ ,c(  \"untreated3\", \"treated3\"   ) ]\n@\n\nNow, without any replicates at all, the \\Rfunction{estimateDispersions} function will refuse to proceed unless we\ninstruct it to ignore the condition labels and estimate the variance by treating all\nsamples as if they were replicates of the same condition:\n<<cds2,cache=TRUE>>=\ncds2 = estimateDispersions( cds2, method=\"blind\", sharingMode=\"fit-only\" )\n@\nNote the option \\texttt{sharingMode=\"fit-only\"}. Remember that the default,\n\\texttt{sharingMode=\"maximum\"}, takes care of outliers, i.e., genes with\ndispersion much larger than the fitted values. Without replicates, we cannot\ncatch such outliers and so have to disable this functionality.\n\nNow, we can attempt to find differential expression:\n<<res2,cache=TRUE>>=\nres2 = nbinomTest( cds2, \"untreated\", \"treated\" )\n@\n\n\\begin{figure}[ht]\n\\centering\n\\includegraphics[width=.6\\textwidth]{DESeq-figDE2}\n\\caption{MvA plot, from a test using no replicates.}\n\\label{figDE2}\n\\end{figure}\n\nUnsurprisingly, we find much fewer hits, as can be seen from the plot (Fig.\\ \\ref{figDE2})\n<<figDE2,fig=TRUE>>=\nplotMA(res2)\n@\nand from this table, tallying the number of significant hits in our previous and our new, restricted analysis:\n<<addmarg>>=\naddmargins( table( res_sig = res$padj < .1, res2_sig = res2$padj < .1 ) )\n@\n\n\n%-------------------------------------------------------------------------------------------------\n\\section{Multi-factor designs} \\label{sec:GLM}\n%-------------------------------------------------------------------------------------------------\nLet us return to the full pasilla data set. Remember that we started of with these data:\n%\n<<reminderFullData>>=\nhead( pasillaCountTable )\npasillaDesign\n@\n\nWhen creating a count data set with multiple factors, just pass a data frame\ninstead of the condition factor:\n\n<<fct>>=\ncdsFull = newCountDataSet( pasillaCountTable, pasillaDesign )\n@\n\nAs before, we estimate the size factors and then the dispersions. Here, the default\nmethod (\\texttt{method=''pooled''} to \\Rfunction{estimateDispersion}), means that,\nas before, one dispersion is computed for each gene,\nwhich is now an average over all cells (weighted by the number of samples for each cells), where\nthe term \\emph{cell} denotes any of the four combinations of factor levels of\nthe design. An alternative is the option \\texttt{method=''pooled-CR''}, which uses\na Cox-Reid-adjusted maximum likelihood estimator \\cite{CR,edgeR_GLM}. The latter is\nslower but useful when the cell concept is not applicable (e.g. in paired designs).\n\n<<estsfdisp,cache=TRUE>>=\ncdsFull = estimateSizeFactors( cdsFull )\ncdsFull = estimateDispersions( cdsFull )\n@\n\n\\begin{figure}[ht]\n\\centering\n\\includegraphics[width=.6\\textwidth]{DESeq-figFitPooled}\n\\caption{Estimated (black) pooled dispersion values for all seven samples, with\nregression curve (red).}\n\\label{figFitPooled}\n\\end{figure}\n\n\nWe check the fit (Fig.~\\ref{figFitPooled}):\n\n<<figFitPooled,fig=TRUE>>=\nplotDispEsts( cdsFull )\n@ %$\n\nFor inference, we now specify two \\emph{models} by formulas. The \\emph{full model}\nregresses the genes' expression on both the library type and\nthe treatment condition, the \\emph{reduced model} regresses them only on the library\ntype. For each gene, we fit generalized linear models (GLMs)\naccording to the two models, and then compare them in order to infer whether\nthe additional specification of the treatment improves the fit and hence, whether\nthe treatment has significant effect.\n\n<<fit1,cache=TRUE,results=hide>>=\nfit1 = fitNbinomGLMs( cdsFull, count ~ libType + condition )\nfit0 = fitNbinomGLMs( cdsFull, count ~ libType  )\n@\nThese commands take a while to execute. Also, they may produce a few warnings,\ninforming you that the GLM fit failed to converge (and the results from these\ngenes should be interpreted with care). The ``fit'' objects are\ndata frames with three columns:\n\n<<fitstr>>=\nstr(fit1)\n@\n\nTo perform the test, we call\n<<pvalsGLM,cache=TRUE>>=\npvalsGLM = nbinomGLMTest( fit1, fit0 )\npadjGLM = p.adjust( pvalsGLM, method=\"BH\" )\n@\n%\n\\fixme{Can we add a paragraph on what to do if we only want to make specific comparisons, e.g.\n  let \\texttt{fac} be a factor with three levels A, B and C, and we want to test pairwise for differences\n  between A and B (without C), between A and C (without B) etc.}\n\nThe function \\Rfunction{nbinomTestGLM} returned simply a vector of $p$ values which\nwe handed to the standard R function \\Rfunction{p.adjust} to adjust for multiple\ntesting using the Benjamini-Hochberg (BH) method.\n\n\\begin{figure}[ht]\n\\centering\n\\includegraphics[width=.5\\textwidth]{DESeq-figDispScatter}\n\\caption{Comparison of per-gene estimates of the dispersion in the\n  analysis using only the four paired-end samples ($x$-axis) and in\n  the analysis using all seven samples ($y$-axis).  For visualisation,\n  the values are on a logarithm-like scale, defined by the function\n  \\Rfunction{trsf}, which is of the form\n  $f(x)=\\log\\left((x+\\sqrt{x^2+1})/2\\right)$. For $x>2$, the values of\n  $f(x)$ and $\\log(x)$ are approximately the same, whereas for values\nof $x$ around 0, $f(x)\\approx x$ is approximated by a straight line of\nslope 1.}\n\\label{figDispScatter}\n\\end{figure}\n\nLet's compare with the result from the four-samples test:\n<<addmarg2>>=\ntab1 = table( \"paired-end only\" = res$padj < .1, \"all samples\" = padjGLM < .1 )\naddmargins( tab1 )\n@\nWe see that the analyses find \\Sexpr{tab1[2,2]} genes in common, while\n\\Sexpr{tab1[1,2]} were only found in the analysis using all samples and\n\\Sexpr{tab1[2,1]} were specific for the \\emph{paired-end only} analysis.\n\nIn this case, the improvement in power that we gained from the additional\nsamples is rather modest. This might indicate that the single-end samples\n(which are presumably older than the paired-end one) are of lower quality.\nThis is supported by the observation that the dispersion estimates in the full\ndata set tend to be larger than in the paired-end only one. So, despite the fact that\nwith 7 samples we gain power from having more degrees of freedom in the estimation of the treatment effect,\nthe additional samples also increase the dispersion (or equivalently, the variance), which loses power.\n%\n<<tablesignfitInfocdsperGeneDispEsts>>=\ntable(sign(fitInfo(cds)$perGeneDispEsts - fitInfo(cdsFull)$perGeneDispEsts))\n@\nSee also Figure~\\ref{figDispScatter}, which is produced by\n%\n<<figDispScatter,fig=TRUE,width=4.5, height=4.5>>=\ntrsf = function(x) log( (x + sqrt(x*x+1))/2 )\nplot( trsf(fitInfo(cds)$perGeneDispEsts),\n      trsf(fitInfo(cdsFull)$perGeneDispEsts), pch=16, cex=0.45, asp=1)\nabline(a=0, b=1, col=\"red3\")\n@\n\nContinuing with the analysis, we can now extract the significant genes\nfrom the vector \\Robject{padjGLM} as before.\nTo see the corresponding fold changes, we have a closer look at the object\n\\Robject{fit1}.\n<<lookatfit1>>=\nhead(fit1)\n@\n\nThe first three columns show the fitted coefficients, converted to a logarithm base 2 scale.\nThe log2 fold change due to the condition is shown in the third column. As indicated\nby the column name, it is the effect of ``untreated'', i.e., the log ratio of\n``untreated'' versus ``treated''. (This is unfortunately the other way round as\nbefore, due to the peculiarities of contrast coding.) Note that the library type also\nhad noticeable influence on the expression, and hence would have increased the dispersion\nestimates (and so reduced power) if we had not fitted an effect for it.\n\nThe column \\emph{deviance}\nis the deviance of the fit. (Comparing the deviances with a $\\chi^2$ likelihood ratio test is\nhow \\Rfunction{nbinomGLMTest} calculates the $p$ values.) The last column, \\emph{converged},\nindicates whether the calculation of coefficients and deviance has fully converged.\n(If it is false too often, you can try to change the GLM control parameters, as\nexplained in the help page to \\Rfunction{fitNbinomGLMs}.)\n\\fixme{This is a bit vague, 'too often' should be specified and ideally the remedy be automated.}\n\nFinally, we show that taking the library type into account was important to have\ngood detection power by doing the analysis again using the standard workflow,\nas outlined earlier, and without informing \\Rpackage{DESeq} of the library types:\n\n<<fullAnalysisSimple,cache=TRUE>>=\ncdsFullB = newCountDataSet( pasillaCountTable, pasillaDesign$condition )\ncdsFullB = estimateSizeFactors( cdsFullB )\ncdsFullB = estimateDispersions( cdsFullB )\nresFullB = nbinomTest( cdsFullB, \"untreated\", \"treated\" )\n<<table>>=\ntab2 = table(\n   `all samples simple` = resFullB$padj < 0.1,\n   `all samples GLM`    = padjGLM < 0.1 )\naddmargins(tab2)\n@ %$\n%\nWe see that the two analyses find \\Sexpr{tab2[2,2]} genes in common,\nwhile in addition \\Sexpr{tab2[1,2]} genes were found by the analysis\nthat took library type into account.  The small number, namely\n\\Sexpr{tab2[2,1]}, of genes that only made the FDR cutoff in the\nsimple analysis is likely due to sampling variation.\n\n%--------------------------------------------------\n\\section{Independent filtering and multiple testing} \\label{sec:indepfilt}\n\\subsection{Filtering by overall count} \\label{sec:filtbycount}\n%--------------------------------------------------\nThe analyses of the previous sections involve the application of\nstatistical tests, one by one, to each row of the data set, in order to\nidentify those genes that have evidence for differential expression.\nThe idea of \\emph{independent filtering} is to filter out those tests\nfrom the procedure that have no, or little chance of showing significant\nevidence, without even looking at their test statistic. Typically, this results in\nincreased detection power at the same experiment-wide type I error.\nHere, we  measure experiment-wide type I error in terms of the false discovery rate.\nA good choice for a filtering criterion is one that\n\\begin{enumerate}\n  \\item\\label{it:indp} is statistically independent from the test statistic\n    under the null hypothesis,\n  \\item\\label{it:corr} is correlated with the test statistic under the\n    alternative, and\n  \\item\\label{it:joint} does not notably change the dependence\n    structure --if there is any--  between the\n    test statistics of nulls and alternatives.\n\\end{enumerate}\nThe benefit from filtering relies on property~\\ref{it:corr}, and we\nwill explore it further in Section~\\ref{sec:whyitworks}. Its\nstatistical validity relies on properties~\\ref{it:indp} and\n\\ref{it:joint}.  We refer to~\\cite{Bourgon:2010:PNAS} for further\ndiscussion on the mathematical and conceptual background.\n%\n<<rs>>=\nrs = rowSums ( counts ( cdsFull ))\ntheta = 0.4\nuse = (rs > quantile(rs, probs=theta))\ntable(use)\ncdsFilt = cdsFull[ use, ]\n@\n<<check,echo=FALSE>>=\nstopifnot(!any(is.na(use)))\n@\n%\nAbove, we consider as a filter criterion \\Robject{rs}, the overall sum\nof counts (irrespective of biological condition), and remove the genes\nin the lowest \\Sexpr{theta*100}\\% quantile (as indicated by the\nparameter \\Robject{theta}).  We perform the testing as before in\nSection~\\ref{sec:GLM}.\n%\n<<fitFilt,cache=TRUE,results=hide>>=\nfitFilt1  = fitNbinomGLMs( cdsFilt, count ~ libType + condition )\nfitFilt0  = fitNbinomGLMs( cdsFilt, count ~ libType  )\npvalsFilt = nbinomGLMTest( fitFilt1, fitFilt0 )\npadjFilt  = p.adjust(pvalsFilt, method=\"BH\" )\n@\n<<doublecheck,echo=FALSE>>=\nstopifnot(all.equal(pvalsFilt, pvalsGLM[use]))\n@\nLet us compare the number of genes found at an FDR of 0.1 by this\nanalysis with that from the previous one (\\Robject{padjGLM}).\n<<tab>>=\npadjFiltForComparison = rep(+Inf, length(padjGLM))\npadjFiltForComparison[use] = padjFilt\ntab3 = table( `no filtering`   = padjGLM < .1,\n             `with filtering` = padjFiltForComparison < .1 )\naddmargins(tab3)\n@\nThe analysis with filtering found an additional \\Sexpr{tab3[1,2]}\ngenes, an increase in the detection rate by about\n\\Sexpr{round(100*tab3[1,2]/tab3[2,2])}\\%,\nwhile \\Sexpr{tab3[2,1]} genes were only found by the previous analysis.\n\n%--------------------------------------------------\n\\subsection{Why does it work?}\\label{sec:whyitworks}\n%--------------------------------------------------\nFirst, consider Figure~\\ref{figscatterindepfilt}, which shows that\namong the 40--45\\% of genes with lowest overall counts, \\Robject{rs},\nthere are essentially none that achieved an (unadjusted) $p$ value less than\n\\Sexpr{signif(quantile(pvalsGLM[!use], 0.0001, na.rm=TRUE), 1)}\n(this corresponds to about \\Sexpr{signif(-log10(quantile(pvalsGLM[!use], 0.0001, na.rm=TRUE)), 2)} on the $-\\log_{10}$-scale).\n%\n<<figscatterindepfilt,fig=TRUE>>=\nplot(rank(rs)/length(rs), -log10(pvalsGLM), pch=16, cex=0.45)\n@\n\\begin{figure}[ht]\n\\centering\n\\includegraphics[width=.5\\textwidth]{DESeq-figscatterindepfilt}\n\\caption{Scatterplot of rank of filter criterion (overall sum of\n  counts \\Robject{rs}) versus the negative logarithm of the test statistic \\Robject{pvalsGLM}.}\n\\label{figscatterindepfilt}\n\\end{figure}\nThis means that by dropping the 40\\% genes with lowest \\Robject{rs},\nwe do not loose anything substantial from our subsequent\nresults. Second, consider the $p$ value histogram in Figure~\\ref{fighistindepfilt}.\nIt shows how the filtering ameliorates the multiple testing problem\n-- and thus the severity of a multiple testing adjustment -- by\nremoving a background set of hypotheses whose $p$ values are distributed\nmore or less uniformly in $[0,1]$.\n<<histindepfilt,width=7,height=5>>=\nh1 = hist(pvalsGLM[!use], breaks=50, plot=FALSE)\nh2 = hist(pvalsGLM[use], breaks=50, plot=FALSE)\ncolori = c(`do not pass`=\"khaki\", `pass`=\"powderblue\")\n<<fighistindepfilt,fig=TRUE>>=\nbarplot(height = rbind(h1$counts, h2$counts), beside = FALSE, col = colori,\n        space = 0, main = \"\", ylab=\"frequency\")\ntext(x = c(0, length(h1$counts)), y = 0, label = paste(c(0,1)), adj = c(0.5,1.7), xpd=NA)\nlegend(\"topright\", fill=rev(colori), legend=rev(names(colori)))\n@\n\\begin{figure}[ht]\n\\centering\n\\includegraphics[width=.5\\textwidth]{DESeq-fighistindepfilt}\n\\caption{Histogram of $p$ values for all tests (\\Robject{pvalsGLM}).\n  The area shaded in blue indicates the subset of those that pass the filtering,\n  the area in khaki those that do not pass.}\n\\label{fighistindepfilt}\n\\end{figure}\n\n%--------------------------------------------------\n\\subsection{How to choose the filter statistic and the cutoff?}\\label{sec:indepfilterchoose}\n%--------------------------------------------------\nPlease refer to the vignette \\emph{Diagnostic plots for independent\n  filtering} in the \\Rpackage{genefilter} package for a discussion on \n\\begin{packeditemize}\n\\item best choice of filter criterion and\n\\item the choice of filter cutoff.  \n\\end{packeditemize}\n\n%---------------------------------------------------\n\\subsection{Diagnostic plots for multiple testing}\n%---------------------------------------------------\nThe Benjamini-Hochberg multiple testing adjustment\nprocedure~\\cite{BH:1995} has a simple graphical illustration, which we\nproduce in the following code chunk. Its result is shown in the left\npanel of Figure~\\ref{figmulttest}.\n%\n<<sortP,cache=TRUE>>=\norderInPlot = order(pvalsFilt)\nshowInPlot = (pvalsFilt[orderInPlot] <= 0.08)\nalpha = 0.1\n<<sortedP,fig=TRUE, width=4.5, height=4.5>>=\nplot(seq(along=which(showInPlot)), pvalsFilt[orderInPlot][showInPlot],\n     pch=\".\", xlab = expression(rank(p[i])), ylab=expression(p[i]))\nabline(a=0, b=alpha/length(pvalsFilt), col=\"red3\", lwd=2)\n@\n<<doBH,echo=FALSE,results=hide>>=\nwhichBH = which(pvalsFilt[orderInPlot] <= alpha*seq(0, 1, length=length(pvalsFilt)))\n## Test some assertions:\n## - whichBH is a contiguous set of integers from 1 to length(whichBH)\n## - the genes selected by this graphical method coincide with those\n##   from p.adjust (i.e. padjFilt)\nstopifnot(length(whichBH)>0,\n          identical(whichBH, seq(along=whichBH)),\n          padjFilt[orderInPlot][ whichBH] <= alpha,\n          padjFilt[orderInPlot][-whichBH]  > alpha)\n@\n%\nSchweder and Spj\\o{}tvoll~\\cite{SchwederSpjotvoll1982} suggested a diagnostic plot\nof the observed $p$-values which permits estimation of the fraction of true null\nhypotheses. For a series of hypothesis tests $H_1, \\ldots, H_m$ with $p$-values\n$p_i$, they suggested plotting\n%\n\\begin{equation}\n  \\left( 1-p_i, N(p_i) \\right) \\mbox{ for } i \\in 1, \\ldots, m,\n\\end{equation}\n%\nwhere $N(p)$ is the number of $p$-values greater than $p$. An application of\nthis diagnostic plot to \\Robject{pvalsFilt} is shown in the right panel of\nFigure~\\ref{figmulttest}.\nWhen all null hypotheses are true, the $p$-values are each uniformly distributed\nin $[0,1]$, Consequently, the cumulative distribution function of $(p_1, \\ldots,\np_m)$ is expected to be close to the line $F(t)=t$. By symmetry, the same\napplies to $(1 - p_1, \\ldots, 1 - p_m)$.\nWhen (without loss of generality) the first $m_0$ null hypotheses are true and\nthe other $m-m_0$ are false, the cumulative distribution function of $(1-p_1,\n\\ldots, 1-p_{m_0})$ is again expected to be close to the line $F_0(t)=t$. The\ncumulative distribution function of $(1-p_{m_0+1}, \\ldots, 1-p_{m})$, on the\nother hand, is expected to be close to a function $F_1(t)$ which stays below\n$F_0$ but shows a steep increase towards 1 as $t$ approaches $1$.\nIn practice, we do not know which of the null hypotheses are true, so we can\nonly observe a mixture whose cumulative distribution function is expected to be\nclose to\n%\n\\begin{equation}\n  F(t) = \\frac{m_0}{m} F_0(t) + \\frac{m-m_0}{m} F_1(t).\n\\end{equation}\n%\n<<SchwSpjot,echo=FALSE,results=hide>>=\nj  = round(length(pvalsFilt)*c(1, .66))\npx = (1-pvalsFilt[orderInPlot[j]])\npy = ((length(pvalsFilt)-1):0)[j]\nslope = diff(py)/diff(px)\n@\n%\nSuch a situation is shown in the right panel of\nFigure~\\ref{figmulttest}. If\n$F_1(t)/F_0(t)$ is small for small $t$, then the mixture fraction\n$\\frac{m_0}{m}$ can be estimated by fitting a line to the left-hand portion of\nthe plot, and then noting its height on the right. Such a fit is shown by the\nred line in the right panel of Figure~\\ref{figmulttest}. Here we used\na value for \\Robject{slope} of \\Sexpr{round(slope)}, the computation\ncan be seen in the \\texttt{.Rnw} source code of this vignette.\n%\n<<SchwederSpjotvoll,fig=TRUE, width=4.5, height=4.5>>=\nplot(1-pvalsFilt[orderInPlot],\n     (length(pvalsFilt)-1):0, pch=\".\",\n     xlab=expression(1-p[i]), ylab=expression(N(p[i])))\nabline(a=0, b=slope, col=\"red3\", lwd=2)\n@\n\n\\begin{figure}[ht]\n\\centering\n\\includegraphics[width=.49\\textwidth]{DESeq-sortedP}\n\\includegraphics[width=.49\\textwidth]{DESeq-SchwederSpjotvoll}\n\\caption{\\emph{Left:} illustration of the Benjamini-Hochberg multiple testing\n  adjustment procedure~\\cite{BH:1995}.  The black line shows the\n  $p$-values ($y$-axis) versus their rank ($x$-axis), starting with\n  the smallest $p$-value from the left, then the second smallest, and\n  so on. Only the first \\Sexpr{sum(showInPlot)} $p$-values are shown.\n  The red line is a straight line with slope $\\alpha/n$, where\n  $n=\\Sexpr{length(pvalsFilt)}$ is the number of tests, and\n  $\\alpha=\\Sexpr{alpha}$ is a target false discovery rate (FDR).  FDR\n  is controlled at the value $\\alpha$ if the genes are selected\n  that lie to the left of the rightmost intersection between the red and black\n  lines: here, this results in \\Sexpr{length(whichBH)} genes.\n  \\emph{Right:} Schweder and Spj\\o{}tvoll plot, as described in the text.\n  For both of these plots, the $p$-values \\Robject{pvalsFilt}\n  from Section~\\ref{sec:filtbycount} were used as a starting\n  point. Analogously, one can produce these types of plots for any set of $p$-values,\n  for instance those from the previous sections.}\n\\label{figmulttest}\n\\end{figure}\n\n%---------------------------------------------------\n\\section{Variance stabilizing transformation}\n%---------------------------------------------------\nFor some applications, it is useful to work with transformed versions\nof the count data. Maybe the most obvious choice is the logarithmic\ntransformation. Since count values for a gene can be zero in some\nconditions (and non-zero in others), some advocate the use of\n\\emph{pseudocounts}, i.\\,e.\\ transformations of the form\n\\begin{equation}\\label{eq:shiftedlog}\n  y = \\log_2(n + 1)\\quad\\mbox{or more generally,}\\quad y = \\log_2(n + n_0),\n\\end{equation}\nwhere $n$ represents the count values and $n_0$ is a somehow chosen\npositive constant. In this section, we discuss a related, alternative\napproach that offers more theoretical justification and a rational way\nof choosing the parameter equivalent to $n_0$ above. It is based on\nerror modeling and the concept of variance stabilizing\ntransformations~\\cite{Tibshirani1988,sagmb2003,Anders:2010:GB}. We\nestimate an overall mean-dispersion relationship of the data using\n\\Rfunction{estimateDispersions} with the argument\n\\Robject{method=\"blind\"} and call the function\n\\Rfunction{getVarianceStabilizedData}.\n%\n<<defvsd>>=\ncdsBlind = estimateDispersions( cds, method=\"blind\" )\nvsd = varianceStabilizingTransformation( cdsBlind )\n@\nHere, we have used a parametric fit for the dispersion. In this case,\nthe a closed-form expression for the variance stabilizing transformation\nis used by \\Rfunction{getVarianceStabilizedData}, which is derived in\nthe document \\texttt{vst.pdf} (you find it in the \\Rpackage{DESeq} package\nalongside this vignette). If a local fit is used (option \\texttt{fittype=\"local\"}\nto \\Rfunction{estimateDispersion}) a numerical integration is used instead.\n%\nThe resulting transformation is shown in\nFigure~\\ref{figvsd1}.  The code that produces the figure is hidden from\nthis vignette for the sake of brevity, but can be seen in the\n\\texttt{.Rnw} or \\texttt{.R} source file.\n%\n\\begin{figure}[ht]\n\\centering\n\\includegraphics[width=.49\\textwidth]{DESeq-vsd1}\n\\caption{Graphs of the variance stabilizing transformation for\n  sample 1, in blue, and of the transformation $f(n)=log_2(n/s_1)$, in\n  black. $n$ are the counts and $s_1$ is the size factor for the first sample.\n}\n\\label{figvsd1}\n\\end{figure}\n\\begin{figure}[ht]\n\\centering\n\\includegraphics[width=\\textwidth]{DESeq-vsd2}\n\\caption{Per-gene standard deviation (taken across samples), against\n  the rank of the mean, for the shifted logarithm\n  $\\log_2(n+1)$ (left) and \\Rpackage{DESeq}'s variance stabilising\n  transformation (right).}\n\\label{figvsd2}\n\\end{figure}\n\n<<vsd1, fig=TRUE, echo=FALSE, width=4.5, height=4.5>>=\n##par(mai=ifelse(1:4 <= 2, par(\"mai\"), 0))\npx     = counts(cds)[,1] / sizeFactors(cds)[1]\nord    = order(px)\nord    = ord[px[ord] < 150]\nord    = ord[seq(1, length(ord), length=50)]\nlast   = ord[length(ord)]\nvstcol = c(\"blue\", \"black\")\nmatplot(px[ord],\n        cbind(exprs(vsd)[, 1], log2(px))[ord, ],\n        type=\"l\", lty=1, col=vstcol, xlab=\"n\", ylab=\"f(n)\")\nlegend(\"bottomright\",\n       legend = c(\n        expression(\"variance stabilizing transformation\"),\n        expression(log[2](n/s[1]))),\n       fill=vstcol)\n@\n%\nFigure~\\ref{figvsd2} plots the standard deviation of the transformed\ndata, across samples, against the mean, first using the shifted\nlogarithm transformation~(\\ref{eq:shiftedlog}), then using\n\\Rpackage{DESeq}'s variance stabilising transformation. While for the\nlatter, the standard deviation is roughly constant along the whole\ndynamic range, the shifted logarithm results in a highly elevated\nstandard deviation in the lower count range.\n%\n<<vsd2, fig=TRUE, width=8.5, height=4.5, results=hide>>=\nlibrary(\"vsn\")\npar(mfrow=c(1,2))\nnotAllZero = (rowSums(counts(cds))>0)\nmeanSdPlot(log2(counts(cds)[notAllZero, ] + 1), ylim = c(0,2.5))\nmeanSdPlot(vsd[notAllZero, ], ylim = c(0,2.5))\n@\n\n%---------------------------------------------------------------\n\\subsection{Application to moderated fold change estimates}\n%---------------------------------------------------------------\nIn the beginning of Section~\\ref{sec:DE}, we have seen in the\n\\Rclass{data.frame} \\Robject{res} the (logarithm base 2) fold change estimate\ncomputed from the size-factor adjusted counts.  When the involved\ncounts are small, these (logarithmic) fold-change estimates can be\nhighly variable, and can even be infinite. For some purposes, such as\nthe clustering of samples or genes according to their expression\nprofiles, or for visualisation of the data, this high variability from\nratios between low counts tends to drown informative, systematic signal\nin other parts of the data.  The variance stabilizing transformation\noffers one way to \\emph{moderate} the fold change estimates, so that\nthey are more amenable to plotting or clustering.\n%\n<<modlr>>=\nmod_lfc = (rowMeans( exprs(vsd)[, conditions(cds)==\"treated\", drop=FALSE] ) -\n           rowMeans( exprs(vsd)[, conditions(cds)==\"untreated\", drop=FALSE] ))\n@\n%\nLet us compare these to the original ($\\log_2$) fold changes. First we\nfind that many of the latter are infinite (resulting from division of\na finite value by 0) or \\emph{not a number} (NaN, resulting from\ndivision of 0 by 0).\n%\n<<dah>>=\nlfc = res$log2FoldChange\ntable(lfc[!is.finite(lfc)], useNA=\"always\")\n@\n%\nFor plotting, let us bin genes by their $\\log_{10}$ mean to colour\nthem according to expression strength,\n%\n<<colourramp>>=\nlogdecade = 1 + round( log10( 1+rowMeans(counts(cdsBlind, normalized=TRUE)) ) )\nlfccol = colorRampPalette( c( \"gray\", \"blue\" ) )(6)[logdecade]\n@\n%\nand then compare their ordinary log-ratios (\\Robject{lfc}) against the\n\\emph{moderated} log-ratios (\\Robject{mod\\_lfc}) in a scatterplot.\n%\n<<figmodlr, fig=TRUE, width=4.5, height=4.5>>=\nymax = 4.5\nplot( pmax(-ymax, pmin(ymax, lfc)), mod_lfc,\n      xlab = \"ordinary log-ratio\", ylab = \"moderated log-ratio\",\n      cex=0.45, asp=1, col = lfccol,\n      pch = ifelse(lfc<(-ymax), 60, ifelse(lfc>ymax, 62, 16)))\nabline( a=0, b=1, col=\"red3\")\n@\nThe result is shown in Figure~\\ref{figmodlr}.\n\\begin{figure}[htb]\n\\centering\n\\includegraphics[width=.5\\textwidth]{DESeq-figmodlr}\n\\caption{Scatterplot of ordinary (\\Robject{lfc}) versus\n  \\emph{moderated} log-ratios (\\Robject{mod\\_lfc}).  The points are\n  coloured in a scale from grey to blue, representing weakly to\n  strongly expressed genes. For the highly expressed genes (blue),\n  \\Robject{lfc} and \\Robject{mod\\_lfc} agree.  Differences arise\n  when the involved counts are small (grey points): in this case, the\n  moderated log-ratio is shrunk towards 0, compared to the ordinary\n  log-ratio.  The $>$ and $<$ symbols correspond to values of\n  \\Robject{lfc} whose absolute value was larger than \\Sexpr{ymax}\n  (including those that were infinite).  All values of\n  \\Robject{mod\\_lfc} vary in a finite range.}\n\\label{figmodlr}\n\\end{figure}\n\n%---------------------------------------------------------------\n\\section{Data quality assessment by sample clustering and visualisation}\\label{sec:quality}\n%---------------------------------------------------------------\nData quality assessment and quality control (i.\\,e.\\ the removal of\ninsufficiently good data) are essential steps of any data\nanalysis. Even though we present these steps towards the end of this vignette,\nthey should typically be performed very early in the analysis of a new data set,\npreceding or in parallel to the differential expression testing.\n\nWe define the term \\emph{quality} as \\emph{fitness for\n  purpose}\\footnote{\\url{http://en.wikipedia.org/wiki/Quality_\\%28business\\%29}}.\nOur purpose is the detection of differentially expressed genes, and we\nare looking in particular for samples whose experimental treatment\nsuffered from an anormality that renders the data points obtained from\nthese particular samples detrimental to our purpose.\n\n\\subsection{Heatmap of the count table}\\label{sec:hmc}\nTo explore a count table, it is often instructive to look at it as a\nheatmap.  Below we show how to produce such a heatmap from the\nvariance stabilisation transformed data for all \\Sexpr{ncol(cdsFull)}\nsamples.\n%\n<<cdsFullBlind,cache=TRUE>>=\ncdsFullBlind = estimateDispersions( cdsFull, method = \"blind\" )\nvsdFull = varianceStabilizingTransformation( cdsFullBlind )\n<<heatmap>>=\nlibrary(\"RColorBrewer\")\nlibrary(\"gplots\")\nselect = order(rowMeans(counts(cdsFull)), decreasing=TRUE)[1:30]\nhmcol = colorRampPalette(brewer.pal(9, \"GnBu\"))(100)\n<<figHeatmap2a,fig=TRUE,width=7,height=10>>=\nheatmap.2(exprs(vsdFull)[select,], col = hmcol, trace=\"none\", margin=c(10, 6))\n@\n%\n\\begin{figure}\n\\centering\n\\includegraphics[width=.49\\textwidth]{DESeq-figHeatmap2a}\n\\includegraphics[width=.49\\textwidth]{DESeq-figHeatmap2b}\n\\caption{Heatmaps showing the expression data of the\n  \\Sexpr{length(select)} most highly expressed genes. Left, the\n  variance stabilisation transformed data (\\Robject{vsdFull}) are\n  shown, right, the original count data (\\Robject{cdsFull}). In the\n  left panel, the sample clustering aligns with the experimental\n  factor (\\emph{treated} / \\emph{untreated}).  The clustering and the\n  colour scale in the right plot is dominated by a small number of data\n  points with large values.}\n\\label{figHeatmap2}\n\\end{figure}\n%\nThe left panel of Figure~\\ref{figHeatmap2} shows the resulting heatmap\nfor the \\Sexpr{length(select)} most highly expressed genes.  For\ncomparison, let us also do the same with the untransformed counts.\n%\n<<figHeatmap2b,fig=TRUE,width=7,height=10>>=\nheatmap.2(counts(cdsFull)[select,], col = hmcol, trace=\"none\", margin=c(10,6))\n@\n\\begin{figure}\n\\centering\n\\includegraphics[width=.6\\textwidth]{DESeq-figHeatmapSamples}\n\\caption{Heatmap showing the Euclidean distances between the samples\n  as calculated from the variance stabilising transformation of the\n  count data.}\n\\label{figHeatmapSamples}\n\\end{figure}\n\n\\subsection{Heatmap of the sample-to-sample distances}\\label{sec:dists}\nAnother use of variance stabilized data is sample clustering. Here, we apply the\n\\Rfunction{dist} function to the transpose of the transformed count matrix to get\nsample-to-sample distances.\n%\n<<sampleClust>>=\ndists = dist( t( exprs(vsdFull) ) )\n@\n%\nA heatmap of this distance matrix gives us an overview over similarities\nand dissimilarities between samples (Figure~\\ref{figHeatmapSamples}):\n\n<<figHeatmapSamples,fig=TRUE,width=7,height=7>>=\nmat = as.matrix( dists )\nrownames(mat) = colnames(mat) = with(pData(cdsFullBlind), paste(condition, libType, sep=\" : \"))\nheatmap.2(mat, trace=\"none\", col = rev(hmcol), margin=c(13, 13))\n@\n%\nThe clustering correctly reflects our experimental design, i.e.,\nsamples are more similar when they have the same treatment or the same\nlibrary type.  (To avoid potential circularities in this conclusion,\nit was important to re-estimate the dispersions with\n\\Robject{method=\"blind\"} in the calculation for \\Robject{cdsFullBlind}\nabove, as only then, the variance stabilizing transformation is not\ninformed about the design, and we can be sure that it is not biased\ntowards a result supporting the design.)\n\n\\subsection{Principal component plot of the samples}\nRelated to the distance matrix of Section~\\ref{sec:dists} is the PCA\nplot of the samples, which we obtain as follows (Figure~\\ref{figPCA}).\n%\n<<figPCA,fig=TRUE,width=5,height=5>>=\nprint(plotPCA(vsdFull, intgroup=c(\"condition\", \"libType\")))\n@\n\\begin{figure}\n\\centering\n\\includegraphics[width=.6\\textwidth]{DESeq-figPCA}\n\\caption{PCA plot. The \\Sexpr{ncol(vsdFull)} samples shown in the 2D\n  plane spanned by their first two principal components. This type of\n  plot is useful for visualizing the overall effect of experimental\n  covariates and batch effects.  For this data set, no batch effects\n  besides the known effects of \\emph{condition} and \\emph{libType} are\n  discernible.}\n\\label{figPCA}\n\\end{figure}\n\n\\subsection{arrayQualityMetrics}\nHeatmaps and PCA plots similar to Figures~\\ref{figHeatmapSamples} and\n\\ref{figPCA} as well as some further diagnostics are also provided by\nthe package \\Rpackage{arrayQualityMetrics}. The package may be\nparticularly useful for larger data set with dozens of\nsamples. You can call its main function, which is also called\n\\Rfunction{arrayQualityMetrics}, with an \\Rclass{ExpressionSet} such\nas \\Robject{vsdFull}, which you will have produced from your\n\\Rclass{CountDataSet} with calls to \\Rfunction{estimateDispersions}\nand \\Rpackage{varianceStabilizingTransformation} as in the beginning\nof Section~\\ref{sec:hmc}.\n\n\\clearpage\n%------------------------------------------------------------\n\\section{Further reading}\\label{sec:further}\n%------------------------------------------------------------\n\nFor more information on the statistical method, see our paper~\\cite{Anders:2010:GB}. For\nmore information on how to customize the \\Rpackage{DESeq} work flow, see the package\nhelp pages, especially the help page for \\Rfunction{estimateDispersions}.\n\n%------------------------------------------------------------\n\\section{Changes since publication of the paper}\\label{sec:changes}\n%------------------------------------------------------------\nSince our paper on \\Rpackage{DESeq} was published in Genome Biology in\nOct 2010, we have made a number of changes to algorithm and\nimplementation, which are listed here.\n\n\\begin{itemize}\n\n\\item \\Rfunction{nbinomTest} calculates a $p$ value by summing up the probabilities\nof all per-group count sums $a$ and $b$ that sum up to the observed count\nsum $k_{iS}$ and are more extreme than the observed count sums $k_{iA}$ and $k_{iB}$.\nEquation~(11) of the paper defined \\emph{more extreme} as those pairs of values $(a,b)$\nthat had smaller probability than the observed pair. This caused problems in cases\nwhere the dispersion exceeded 1. Hence, we now sum instead the probabilities of all\nvalues pairs that are \\emph{further out} in the sense that they cause a more extreme\nfold change $(a/s_A)/(b/s_B)$, where $s_A$ and $s_B$ are the sums of the size factors of\nthe samples in conditions $A$ and $B$, respectively. We do this in a one-tailed manner and\ndouble the result. Furthermore, we no longer approximate the sum, but always\ncalculate it exactly.\n\n\\item We added the possibility to fit GLMs of the negative binomial\nfamily with log link.\nThis new functionality is described in this vignette. $p$ values are calculated by a\n$\\chi^2$ likelihood ratio test. The logarithms of the size factors\nare provided as offsets to the GLM fitting function.\n\n\\item The option \\texttt{sharingMode='maximum'} was added to \\Rfunction{estimateDispersion}\nand made default. This change makes DESeq robust against variance outliers and was not yet\ndiscussed in the paper.\n\n\\item By default, DESeq now estimates one pooled dispersion estimate across all\n(replicated) conditions. In the original version, we estimated a separate\ndispersion-mean relation for each condition. The ``maximum'' sharing mode achieves\nits goal of making DESeq robust against outliers only with pooled dispersion\nestimate, and hence, this is now the default. The option \\texttt{method='per-condition'} to\n\\Rfunction{estimateDispersions} allows the user to go back to the old method.\n\n\\item In the paper, the mean-dispersion relation is fitted by local regression. Now,\nDESeq also offers a parametric regression, as described in this vignette. The option\n\\texttt{fitType} to \\Rfunction{estimateDispersions} allows the user to choose between these.\nIf a parametric regression is used, the variance stabilizing transformation is calculated\nusing the closed-form expression given in the vignette supplement file \\texttt{vst.pdf}.\n\n\\item Finally, instead of the term \\emph{raw squared coefficient of variance}\nused in the paper we now prefer the more standard term \\emph{dispersion}.\n\n\\end{itemize}\n\n\\section{Session Info}\n<<sessi>>=\nsessionInfo()\n@\n\n\\bibliographystyle{unsrt}\n\\bibliography{DESeq}\n\n\n\\end{document}\n",
    "created" : 1383957413495.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "593559572",
    "id" : "E93DF064",
    "lastKnownWriteTime" : 1383781856,
    "path" : "~/Desktop/DESeq.Rnw",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "sweave"
}